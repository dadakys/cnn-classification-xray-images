{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadakys/cnn-classification-xray-images/blob/main/xray_classification_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install dependencies\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# ğŸ“ Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ğŸ§­ Set the path to your dataset on Google Drive\n",
        "drive_data_dir = \"/content/drive/MyDrive/SXOLH2/ex8/Neural_Networks/COVID-19_Radiography_Dataset\"\n",
        "\n",
        "# ğŸ“¥ Copy dataset to Colab's local storage (faster access)\n",
        "local_data_dir = \"/content/COVID-19_Radiography_Dataset\"\n",
        "\n",
        "if not os.path.exists(local_data_dir):  # avoid copying multiple times\n",
        "    print(\"ğŸ“¥ Copying dataset to Colab local storage...\")\n",
        "    shutil.copytree(drive_data_dir, local_data_dir)\n",
        "else:\n",
        "    print(\"âœ… Dataset already in local storage.\")\n",
        "\n",
        "# ğŸ“ Now use local_data_dir for loading images (not Google Drive anymore)\n",
        "data_dir = local_data_dir\n"
      ],
      "metadata": {
        "id": "cznwYtUy7AJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NM-yGkEK3iR"
      },
      "outputs": [],
      "source": [
        "#check the hardware used\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "agvwYU5DPaYy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create  dataframe excluding masks (collect dataset)\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "for label in os.listdir(data_dir):\n",
        "    label_path = os.path.join(data_dir, label)\n",
        "    if not os.path.isdir(label_path):\n",
        "        continue\n",
        "\n",
        "    for subfolder in os.listdir(label_path):\n",
        "        sub_path = os.path.join(label_path, subfolder)\n",
        "        if subfolder.lower() == 'masks':\n",
        "            continue\n",
        "\n",
        "        if os.path.isdir(sub_path):\n",
        "            for file in os.listdir(sub_path):\n",
        "                if file.endswith('.png'):\n",
        "                    filepaths.append(os.path.join(sub_path, file))\n",
        "                    labels.append(label)\n",
        "        elif subfolder.endswith('.png'):\n",
        "            filepaths.append(sub_path)\n",
        "            labels.append(label)\n",
        "\n",
        "df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "\n",
        "print(f\"âœ… Collected {len(df)} images!\")\n",
        "print(df['labels'].value_counts())\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "LerR4rWqTB59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot images per class\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# ğŸ“Š Get one sample per unique class\n",
        "sample_df = df.groupby(\"labels\").apply(lambda x: x.sample(1, random_state=42)).reset_index(drop=True)\n",
        "\n",
        "# ğŸ¨ Plot the images\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i, row in enumerate(sample_df.itertuples()):\n",
        "    img = cv2.imread(row.filepaths)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(row.labels)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Images from Each Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RB2SxDnmxLFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#images class distribution\n",
        "#VISUALIZATIONS\n",
        "# Churn distribution with value labels\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(6, 5))\n",
        "ax = sns.countplot(data=df, x='labels')\n",
        "plt.title('Dataset Class Distribution')\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Images')\n",
        "\n",
        "# Add count labels on top of each bar\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(p.get_x() + p.get_width() / 2., height + 100, int(height), ha=\"center\", fontsize=12)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X7yJz-Y-Scp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8qZigbBokm-"
      },
      "outputs": [],
      "source": [
        "  # Split the dataset with stratified folds\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "  K = 4\n",
        "  skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "  folds = []\n",
        "\n",
        "  for train_idx, test_idx in skf.split(df['filepaths'], df['labels']):\n",
        "      train_data = df.iloc[train_idx].reset_index(drop=True)\n",
        "      test_data = df.iloc[test_idx].reset_index(drop=True)\n",
        "      folds.append((train_data, test_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkocWsFmRC4b"
      },
      "outputs": [],
      "source": [
        "#Add data augmentation and normalize images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4JURrns_bcg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Enable mixed precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24S47357sSMK"
      },
      "outputs": [],
      "source": [
        "#UPDATED\n",
        "#CNN from scratch\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# â¡ï¸ Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î½Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î½Î­Î¿ \"ÎºÎ±Î¸Î±ÏÏŒ\" Î¼Î¿Î½Ï„Î­Î»Î¿ ÎºÎ¬Î¸Îµ Ï†Î¿ÏÎ¬\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # ğŸ”¹ Conv Layer 1\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # ğŸ”¹ Conv Layer 2\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # ğŸ”¹ Conv Layer 3\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # ğŸ”¹ Flatten ÎºÎ±Î¹ Fully Connected\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # ğŸ”¹ Output Layer\n",
        "    model.add(Dense(4, activation='softmax', dtype='float32'))\n",
        "\n",
        "    # âœ… Compile\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0005),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # ğŸ“Š Summary\n",
        "    model.summary()\n",
        "\n",
        "    # ğŸ–¼ï¸ Plot architecture to file\n",
        "    plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MobileNetV2\n",
        "# ================================================================\n",
        "# Transfer-learning baseline: MobileNet V2 on 4-fold CXR dataset\n",
        "# ================================================================\n",
        "#\n",
        "# âŠ   Uses ImageNet weights, input 224Ã—224Ã—3.\n",
        "# â‹   Correct MobileNetV2 preprocessing (scales pixels to [-1, 1]).\n",
        "# âŒ   Two-phase training:\n",
        "#        Â· Phase-1: head only, base frozen\n",
        "#        Â· Phase-2: unfreeze last 30 non-BatchNorm layers\n",
        "# â   Mixed-precision enabled (float16 compute, float32 logits)\n",
        "# â   Checkpoints best weights each fold so you can resume.\n",
        "# â   Evaluates on *clean* Train, Validation, Test generators.\n",
        "# â   Appends metrics to the existing results.csv.\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "import os, time, pickle, tensorflow as tf, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# â”€â”€â”€ mixed precision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# â”€â”€â”€ hyper-parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "IMG_SIZE          = (224, 224)\n",
        "BATCH_SIZE        = 64          # fits easily on T4/L4; raise if you have spare VRAM\n",
        "EPOCHS_FROZEN     = 10\n",
        "EPOCHS_FINE_TUNE  = 20\n",
        "UNFREEZE_LAYERS   = 30          # last N layers to train (skip BatchNorm)\n",
        "RESULTS_CSV       = \"/content/drive/MyDrive/saved_models/results.csv\"\n",
        "TECHNIQUE_NAME    = \"MobileNetV2\"\n",
        "\n",
        "# â”€â”€â”€ data generators (MobileNetV2 needs [-1,1] scaling) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=10, zoom_range=0.1,\n",
        "    width_shift_range=0.1, height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# â”€â”€â”€ load / init results dataframe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if os.path.exists(RESULTS_CSV):\n",
        "    results_df = pd.read_csv(RESULTS_CSV)\n",
        "else:\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Technique\", \"Set\", \"Fold\", \"Time(min)\", \"Epochs Trained\",\n",
        "        \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "# â”€â”€â”€ model-builder function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(num_classes: int):\n",
        "    base = MobileNetV2(include_top=False,\n",
        "                       weights='imagenet',\n",
        "                       input_shape=IMG_SIZE + (3,))\n",
        "    base.trainable = False                       # phase-1: frozen\n",
        "\n",
        "    inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x = base(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(1e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model, base\n",
        "\n",
        "# â”€â”€â”€ helper: evaluation & CSV append â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def evaluate_and_log(set_name, generator, fold_idx, elapsed, epochs_done):\n",
        "    y_true = generator.classes\n",
        "    y_pred = model.predict(generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "    new_row = {\n",
        "        \"Technique\"     : TECHNIQUE_NAME,\n",
        "        \"Set\"           : set_name,\n",
        "        \"Fold\"          : fold_idx,\n",
        "        \"Time(min)\"     : round(elapsed, 2),\n",
        "        \"Epochs Trained\": epochs_done,\n",
        "        \"Accuracy\"      : accuracy_score(y_true, y_pred),\n",
        "        \"Precision\"     : precision_score(y_true, y_pred, average='weighted'),\n",
        "        \"Recall\"        : recall_score(y_true, y_pred, average='weighted'),\n",
        "        \"F1 Score\"      : f1_score(y_true, y_pred, average='weighted')\n",
        "    }\n",
        "    global results_df\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([new_row])],\n",
        "                           ignore_index=True)\n",
        "\n",
        "# â”€â”€â”€ callbacks template â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "def make_callbacks(fold_idx):\n",
        "    ckpt_path = f\"/content/drive/MyDrive/saved_models/tl_mnv2_fold{fold_idx}_best.weights.h5\"\n",
        "    return [\n",
        "        EarlyStopping(monitor='val_loss', patience=3,\n",
        "                      restore_best_weights=True, verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                          patience=2, verbose=1),\n",
        "        ModelCheckpoint(ckpt_path, save_best_only=False,\n",
        "                        save_weights_only=True, monitor='val_loss', verbose=1)\n",
        "    ]\n",
        "\n",
        "# â”€â”€â”€ 4-fold cross-validation loop (uses your existing â€œfoldsâ€) â”€â”€\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds, start=1):\n",
        "    print(f\"\\nğŸš€  Fold {fold_idx} / {len(folds)}\\n\")\n",
        "\n",
        "    # split off 10 % validation\n",
        "    train_split_df, val_split_df = train_test_split(\n",
        "        train_df, test_size=0.10, stratify=train_df['labels'], random_state=42)\n",
        "\n",
        "    # generators\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_split_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=True)\n",
        "\n",
        "    val_gen = val_datagen.flow_from_dataframe(\n",
        "        val_split_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        test_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "\n",
        "    # clean (non-augmented) train generator for metrics\n",
        "    train_clean_gen = val_datagen.flow_from_dataframe(\n",
        "        train_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "\n",
        "    model, base_model = build_model(len(train_gen.class_indices))\n",
        "\n",
        "    # â”€â”€ phase-1: head only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    start_time = time.time()\n",
        "    history1 = model.fit(\n",
        "        train_gen, validation_data=val_gen,\n",
        "        epochs=EPOCHS_FROZEN, callbacks=make_callbacks(fold_idx), verbose=1)\n",
        "\n",
        "    # â”€â”€ phase-2: fine-tune last N conv layers (skip BatchNorm) â”€â”€\n",
        "    opened = 0\n",
        "    for layer in reversed(base_model.layers):\n",
        "        if opened >= UNFREEZE_LAYERS: break\n",
        "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "            opened += 1\n",
        "\n",
        "    model.compile(optimizer=Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    start_ft = len(history1.history['loss'])\n",
        "    history2 = model.fit(\n",
        "        train_gen, validation_data=val_gen,\n",
        "        initial_epoch=start_ft, epochs=start_ft + EPOCHS_FINE_TUNE,\n",
        "        callbacks=make_callbacks(fold_idx), verbose=1)\n",
        "\n",
        "    total_epochs = len(history1.history['loss']) + len(history2.history['loss'])\n",
        "    elapsed_min  = (time.time() - start_time) / 60\n",
        "\n",
        "    # â”€â”€ save merged history & final model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    hist = {k: history1.history[k] + history2.history[k] for k in history1.history}\n",
        "    with open(f\"/content/drive/MyDrive/saved_models/mnv2_history_fold{fold_idx}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(hist, f)\n",
        "    model.save(f\"/content/drive/MyDrive/saved_models/mnv2_fold{fold_idx}.h5\")\n",
        "\n",
        "    # â”€â”€ evaluation & CSV logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    evaluate_and_log(\"Train-clean\", train_clean_gen, fold_idx, elapsed_min, total_epochs)\n",
        "    evaluate_and_log(\"Validation\",   val_gen,       fold_idx, elapsed_min, total_epochs)\n",
        "    evaluate_and_log(\"Test\",         test_gen,      fold_idx, elapsed_min, total_epochs)\n",
        "\n",
        "    results_df.to_csv(RESULTS_CSV, index=False)\n",
        "    print(f\"âœ…  Fold {fold_idx} done â€” results appended.\\n\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EfIIkO0QGZIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DenseNet121\n",
        "\n",
        "import os, time, pickle, tensorflow as tf, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# â”€â”€â”€ mixed precision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# â”€â”€â”€ hyper-parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "IMG_SIZE          = (224, 224)\n",
        "BATCH_SIZE        = 48          # fits easily on T4/L4; raise if you have spare VRAM\n",
        "EPOCHS_FROZEN     = 10\n",
        "EPOCHS_FINE_TUNE  = 20\n",
        "UNFREEZE_LAYERS   = 100         # last N layers to train (skip BatchNorm)\n",
        "RESULTS_CSV       = \"/content/drive/MyDrive/saved_models/results.csv\"\n",
        "TECHNIQUE_NAME    = \"DenseNet121\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=10, zoom_range=0.1,\n",
        "    width_shift_range=0.1, height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# â”€â”€â”€ load / init results dataframe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if os.path.exists(RESULTS_CSV):\n",
        "    results_df = pd.read_csv(RESULTS_CSV)\n",
        "else:\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Technique\", \"Set\", \"Fold\", \"Time(min)\", \"Epochs Trained\",\n",
        "        \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "# â”€â”€â”€ model-builder function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(num_classes: int):\n",
        "    base = DenseNet121(include_top=False,\n",
        "                       weights='imagenet',\n",
        "                       input_shape=IMG_SIZE + (3,))\n",
        "    base.trainable = False                       # phase-1: frozen\n",
        "\n",
        "    inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x = base(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(1e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model, base\n",
        "\n",
        "# â”€â”€â”€ helper: evaluation & CSV append â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def evaluate_and_log(set_name, generator, fold_idx, elapsed, epochs_done):\n",
        "    y_true = generator.classes\n",
        "    y_pred = model.predict(generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "    new_row = {\n",
        "        \"Technique\"     : TECHNIQUE_NAME,\n",
        "        \"Set\"           : set_name,\n",
        "        \"Fold\"          : fold_idx,\n",
        "        \"Time(min)\"     : round(elapsed, 2),\n",
        "        \"Epochs Trained\": epochs_done,\n",
        "        \"Accuracy\"      : accuracy_score(y_true, y_pred),\n",
        "        \"Precision\"     : precision_score(y_true, y_pred, average='weighted'),\n",
        "        \"Recall\"        : recall_score(y_true, y_pred, average='weighted'),\n",
        "        \"F1 Score\"      : f1_score(y_true, y_pred, average='weighted')\n",
        "    }\n",
        "    global results_df\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([new_row])],\n",
        "                           ignore_index=True)\n",
        "\n",
        "# â”€â”€â”€ callbacks template â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "def make_callbacks(fold_idx):\n",
        "    ckpt_path = f\"/content/drive/MyDrive/saved_models/tl_d121_fold{fold_idx}_best.weights.h5\"\n",
        "    return [\n",
        "        EarlyStopping(monitor='val_loss', patience=3,\n",
        "                      restore_best_weights=True, verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                          patience=2, verbose=1),\n",
        "        ModelCheckpoint(ckpt_path, save_best_only=False,\n",
        "                        save_weights_only=True, monitor='val_loss', verbose=1)\n",
        "    ]\n",
        "\n",
        "# â”€â”€â”€ 4-fold cross-validation loop (uses your existing â€œfoldsâ€) â”€â”€\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds, start=1):\n",
        "    print(f\"\\nğŸš€  Fold {fold_idx} / {len(folds)}\\n\")\n",
        "\n",
        "    # split off 10 % validation\n",
        "    train_split_df, val_split_df = train_test_split(\n",
        "        train_df, test_size=0.10, stratify=train_df['labels'], random_state=42)\n",
        "\n",
        "    # generators\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_split_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=True)\n",
        "\n",
        "    val_gen = val_datagen.flow_from_dataframe(\n",
        "        val_split_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        test_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "\n",
        "    # clean (non-augmented) train generator for metrics\n",
        "    train_clean_gen = val_datagen.flow_from_dataframe(\n",
        "        train_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "\n",
        "    model, base_model = build_model(len(train_gen.class_indices))\n",
        "\n",
        "    # â”€â”€ phase-1: head only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    start_time = time.time()\n",
        "    history1 = model.fit(\n",
        "        train_gen, validation_data=val_gen,\n",
        "        epochs=EPOCHS_FROZEN, callbacks=make_callbacks(fold_idx), verbose=1)\n",
        "\n",
        "    # â”€â”€ phase-2: fine-tune last N conv layers (skip BatchNorm) â”€â”€\n",
        "    opened = 0\n",
        "    for layer in reversed(base_model.layers):\n",
        "        if opened >= UNFREEZE_LAYERS: break\n",
        "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "            opened += 1\n",
        "\n",
        "    model.compile(optimizer=Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    start_ft = len(history1.history['loss'])\n",
        "    history2 = model.fit(\n",
        "        train_gen, validation_data=val_gen,\n",
        "        initial_epoch=start_ft, epochs=start_ft + EPOCHS_FINE_TUNE,\n",
        "        callbacks=make_callbacks(fold_idx), verbose=1)\n",
        "\n",
        "    total_epochs = len(history1.history['loss']) + len(history2.history['loss'])\n",
        "    elapsed_min  = (time.time() - start_time) / 60\n",
        "\n",
        "    # â”€â”€ save merged history & final model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    hist = {k: history1.history[k] + history2.history[k] for k in history1.history}\n",
        "    with open(f\"/content/drive/MyDrive/saved_models/mnv2_history_fold{fold_idx}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(hist, f)\n",
        "    model.save(f\"/content/drive/MyDrive/saved_models/mnv2_fold{fold_idx}.h5\")\n",
        "\n",
        "    # â”€â”€ evaluation & CSV logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    evaluate_and_log(\"Train-clean\", train_clean_gen, fold_idx, elapsed_min, total_epochs)\n",
        "    evaluate_and_log(\"Validation\",   val_gen,       fold_idx, elapsed_min, total_epochs)\n",
        "    evaluate_and_log(\"Test\",         test_gen,      fold_idx, elapsed_min, total_epochs)\n",
        "\n",
        "    results_df.to_csv(RESULTS_CSV, index=False)\n",
        "    print(f\"âœ…  Fold {fold_idx} done â€” results appended.\\n\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jPAw-GiQtRaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === EfficientNetB0 Transfer Learning with 4-Fold CV ===\n",
        "\n",
        "import os, time, pickle, tensorflow as tf, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# â”€â”€â”€ mixed precision (optional, saves VRAM on Colab) â”€â”€â”€\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# â”€â”€â”€ hyperparameters & paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS_FROZEN = 10\n",
        "EPOCHS_FINE_TUNE = 20\n",
        "UNFREEZE_LAYERS = 30\n",
        "RESULTS_CSV = \"/content/drive/MyDrive/saved_models/results.csv\"\n",
        "TECHNIQUE_NAME = \"EfficientNetB0\"\n",
        "\n",
        "# â”€â”€â”€ Data generators â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=10, zoom_range=0.1,\n",
        "    width_shift_range=0.1, height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# â”€â”€â”€ Load or init results CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if os.path.exists(RESULTS_CSV):\n",
        "    results_df = pd.read_csv(RESULTS_CSV)\n",
        "else:\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Technique\", \"Set\", \"Fold\", \"Time(min)\", \"Epochs Trained\",\n",
        "        \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"\n",
        "    ])\n",
        "\n",
        "# â”€â”€â”€ Model builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(num_classes: int):\n",
        "    base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=IMG_SIZE + (3,))\n",
        "    base.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x = base(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(1e-4), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model, base\n",
        "\n",
        "# â”€â”€â”€ Evaluation helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def evaluate_and_log(set_name, generator, fold_idx, elapsed, epochs_done):\n",
        "    y_true = generator.classes\n",
        "    y_pred = model.predict(generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "    new_row = {\n",
        "        \"Technique\": TECHNIQUE_NAME,\n",
        "        \"Set\": set_name,\n",
        "        \"Fold\": fold_idx,\n",
        "        \"Time(min)\": round(elapsed, 2),\n",
        "        \"Epochs Trained\": epochs_done,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"F1 Score\": f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    }\n",
        "    global results_df\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "# â”€â”€â”€ Callbacks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "def make_callbacks(fold_idx):\n",
        "    ckpt_path = f\"/content/drive/MyDrive/saved_models/effb0_fold{fold_idx}_best.weights.h5\"\n",
        "    return [\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=2, verbose=1),\n",
        "        ModelCheckpoint(ckpt_path, save_best_only=False, save_weights_only=True,\n",
        "                        monitor=\"val_loss\", verbose=1)\n",
        "    ]\n",
        "\n",
        "# â”€â”€â”€ Training loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds, start=1):\n",
        "    print(f\"\\nğŸš€ Fold {fold_idx} / {len(folds)} â€” EfficientNetB0\\n\")\n",
        "\n",
        "    # 10% validation split from training\n",
        "    train_split_df, val_split_df = train_test_split(\n",
        "        train_df, test_size=0.10, stratify=train_df[\"labels\"], random_state=42)\n",
        "\n",
        "    # Data generators\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_split_df, x_col=\"filepaths\", y_col=\"labels\",\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode=\"categorical\", shuffle=True)\n",
        "\n",
        "    val_gen = val_datagen.flow_from_dataframe(\n",
        "        val_split_df, x_col=\"filepaths\", y_col=\"labels\",\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode=\"categorical\", shuffle=False)\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        test_df, x_col=\"filepaths\", y_col=\"labels\",\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode=\"categorical\", shuffle=False)\n",
        "\n",
        "    train_clean_gen = val_datagen.flow_from_dataframe(\n",
        "        train_df, x_col=\"filepaths\", y_col=\"labels\",\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode=\"categorical\", shuffle=False)\n",
        "\n",
        "    model, base_model = build_model(len(train_gen.class_indices))\n",
        "\n",
        "    # Phase 1: frozen base\n",
        "    start_time = time.time()\n",
        "    history1 = model.fit(train_gen, validation_data=val_gen,\n",
        "                         epochs=EPOCHS_FROZEN, callbacks=make_callbacks(fold_idx), verbose=1)\n",
        "\n",
        "    # Phase 2: fine-tune last N layers (skip BatchNorm)\n",
        "    opened = 0\n",
        "    for layer in reversed(base_model.layers):\n",
        "        if opened >= UNFREEZE_LAYERS:\n",
        "            break\n",
        "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "            opened += 1\n",
        "\n",
        "    model.compile(optimizer=Adam(1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    start_ft = len(history1.history[\"loss\"])\n",
        "    history2 = model.fit(train_gen, validation_data=val_gen,\n",
        "                         initial_epoch=start_ft, epochs=start_ft + EPOCHS_FINE_TUNE,\n",
        "                         callbacks=make_callbacks(fold_idx), verbose=1)\n",
        "\n",
        "    # Save\n",
        "    total_epochs = len(history1.history[\"loss\"]) + len(history2.history[\"loss\"])\n",
        "    elapsed_min = (time.time() - start_time) / 60\n",
        "\n",
        "    hist = {k: history1.history[k] + history2.history[k] for k in history1.history}\n",
        "    with open(f\"/content/drive/MyDrive/saved_models/effb0_history_fold{fold_idx}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(hist, f)\n",
        "\n",
        "    model.save(f\"/content/drive/MyDrive/saved_models/effb0_fold{fold_idx}.h5\")\n",
        "\n",
        "    # Evaluation\n",
        "    evaluate_and_log(\"Train-clean\", train_clean_gen, fold_idx, elapsed_min, total_epochs)\n",
        "    evaluate_and_log(\"Validation\", val_gen, fold_idx, elapsed_min, total_epochs)\n",
        "    evaluate_and_log(\"Test\", test_gen, fold_idx, elapsed_min, total_epochs)\n",
        "\n",
        "    results_df.to_csv(RESULTS_CSV, index=False)\n",
        "    print(f\"âœ… Fold {fold_idx} complete. Results saved.\\n\")\n"
      ],
      "metadata": {
        "id": "q9PxRhR1CNbn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Transfer-learning baseline: VGG-19 on 4-fold CXR dataset\n",
        "# ================================================================\n",
        "#\n",
        "# âŠ   ImageNet weights, input 224Ã—224Ã—3.\n",
        "# â‹   Proper VGG19 preprocessing (mean-subtraction, RGB->BGR).\n",
        "# âŒ   Two-phase training:\n",
        "#        Â· Phase-1: head only, base frozen\n",
        "#        Â· Phase-2: unfreeze last 8 conv layers\n",
        "# â   Mixed precision enabled (float16 compute, float32 logits).\n",
        "# â   Checkpoints best weights each fold so you can resume.\n",
        "# â   Evaluates on clean Train, Validation, Test generators.\n",
        "# â   Appends metrics to the existing results.csv.\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "import os, time, pickle, tensorflow as tf, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# â”€â”€â”€ mixed precision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# â”€â”€â”€ hyper-parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "IMG_SIZE          = (224, 224)\n",
        "BATCH_SIZE        = 32            # VGG19 is heavy; 32 fits on Colab T4/L4\n",
        "EPOCHS_FROZEN     = 5\n",
        "EPOCHS_FINE_TUNE  = 15\n",
        "UNFREEZE_LAYERS   = 8             # last 8 conv layers\n",
        "RESULTS_CSV       = \"/content/drive/MyDrive/saved_models/results.csv\"\n",
        "TECHNIQUE_NAME    = \"TL-VGG19\"\n",
        "\n",
        "# â”€â”€â”€ data generators (VGG19 preprocess) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=10, zoom_range=0.1,\n",
        "    width_shift_range=0.1, height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# â”€â”€â”€ load / init results dataframe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if os.path.exists(RESULTS_CSV):\n",
        "    results_df = pd.read_csv(RESULTS_CSV)\n",
        "else:\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Technique\", \"Set\", \"Fold\", \"Time(min)\", \"Epochs Trained\",\n",
        "        \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "# â”€â”€â”€ model-builder function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(num_classes: int):\n",
        "    base = VGG19(include_top=False,\n",
        "                 weights='imagenet',\n",
        "                 input_shape=IMG_SIZE + (3,))\n",
        "    base.trainable = False                        # phase-1: frozen\n",
        "\n",
        "    inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x = base(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(1e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model, base\n",
        "\n",
        "# â”€â”€â”€ evaluation helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def evaluate_and_log(set_name, generator, fold_idx, elapsed, epochs_done):\n",
        "    y_true = generator.classes\n",
        "    y_pred = model.predict(generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "    new_row = {\n",
        "        \"Technique\"     : TECHNIQUE_NAME,\n",
        "        \"Set\"           : set_name,\n",
        "        \"Fold\"          : fold_idx,\n",
        "        \"Time(min)\"     : round(elapsed, 2),\n",
        "        \"Epochs Trained\": epochs_done,\n",
        "        \"Accuracy\"      : accuracy_score(y_true, y_pred),\n",
        "        \"Precision\"     : precision_score(y_true, y_pred, average='weighted'),\n",
        "        \"Recall\"        : recall_score(y_true, y_pred, average='weighted'),\n",
        "        \"F1 Score\"      : f1_score(y_true, y_pred, average='weighted')\n",
        "    }\n",
        "    global results_df\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([new_row])],\n",
        "                           ignore_index=True)\n",
        "\n",
        "# â”€â”€â”€ callbacks template â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "def make_callbacks(fold_idx):\n",
        "    ckpt_path = f\"/content/drive/MyDrive/saved_models/tl_vgg19_fold{fold_idx}_best.weights.h5\"\n",
        "    return [\n",
        "        EarlyStopping(monitor='val_loss', patience=3,\n",
        "                      restore_best_weights=True, verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                          patience=2, verbose=1),\n",
        "        ModelCheckpoint(ckpt_path, save_best_only=True,\n",
        "                        save_weights_only=True, monitor='val_loss', verbose=1)\n",
        "    ]\n",
        "\n",
        "# â”€â”€â”€ 4-fold cross-validation loop (uses your existing â€œfoldsâ€) â”€â”€\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds, start=1):\n",
        "    print(f\"\\nğŸš€  Fold {fold_idx} / {len(folds)}\\n\")\n",
        "\n",
        "    # split off 10 % validation\n",
        "    train_split_df, val_split_df = train_test_split(\n",
        "        train_df, test_size=0.10, stratify=train_df['labels'], random_state=42)\n",
        "\n",
        "    # generators\n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        train_split_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=True)\n",
        "\n",
        "    val_gen = val_datagen.flow_from_dataframe(\n",
        "        val_split_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        test_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "\n",
        "    train_clean_gen = val_datagen.flow_from_dataframe(\n",
        "        train_df, x_col='filepaths', y_col='labels',\n",
        "        target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "    num_classes = len(train_gen.class_indices)   # robust across TF versions\n",
        "    model, base_model = build_model(num_classes)\n",
        "\n",
        "\n",
        "\n",
        "    # â”€â”€ phase-1: head only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    start_time = time.time()\n",
        "    history1 = model.fit(\n",
        "        train_gen, validation_data=val_gen,\n",
        "        epochs=EPOCHS_FROZEN, callbacks=make_callbacks(fold_idx), verbose=1)\n",
        "\n",
        "    # â”€â”€ phase-2: fine-tune last N conv layers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    opened = 0\n",
        "    for layer in reversed(base_model.layers):\n",
        "        if opened >= UNFREEZE_LAYERS: break\n",
        "        if 'conv' in layer.name:\n",
        "            layer.trainable = True\n",
        "            opened += 1\n",
        "\n",
        "    model.compile(optimizer=Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    start_ft = len(history1.history['loss'])\n",
        "    history2 = model.fit(\n",
        "        train_gen, validation_data=val_gen,\n",
        "        initial_epoch=start_ft, epochs=start_ft + EPOCHS_FINE_TUNE,\n",
        "        callbacks=make_callbacks(fold_idx), verbose=1)\n",
        "\n",
        "    total_epochs = len(history1.history['loss']) + len(history2.history['loss'])\n",
        "    elapsed_min  = (time.time() - start_time) / 60\n",
        "\n",
        "    # â”€â”€ save history & model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    hist = {k: history1.history[k] + history2.history[k] for k in history1.history}\n",
        "    with open(f\"/content/drive/MyDrive/saved_models/vgg19_history_fold{fold_idx}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(hist, f)\n",
        "    model.save(f\"/content/drive/MyDrive/saved_models/vgg19_fold{fold_idx}.h5\")\n",
        "\n",
        "    # â”€â”€ evaluation & CSV logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    evaluate_and_log(\"Train-clean\", train_clean_gen, fold_idx, elapsed_min, total_epochs)\n",
        "    evaluate_and_log(\"Validation\",   val_gen,       fold_idx, elapsed_min, total_epochs)\n",
        "    evaluate_and_log(\"Test\",         test_gen,      fold_idx, elapsed_min, total_epochs)\n",
        "\n",
        "    results_df.to_csv(RESULTS_CSV, index=False)\n",
        "    print(f\"âœ…  Fold {fold_idx} done â€” results appended.\\n\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AmVFsKQN2xW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "#Plot accuracy and Loss Curves for 1 fold\n",
        "# Load history\n",
        "with open('/content/drive/MyDrive/saved_models/mnv2_history_fold3.pkl', 'rb') as f: #changed based on CNN and fold\n",
        "    history = pickle.load(f)\n",
        "\n",
        "# Plot loss\n",
        "plt.plot(history['loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.title('Fold 3 - Loss Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy\n",
        "plt.plot(history['accuracy'], label='Train Acc')\n",
        "plt.plot(history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Fold 3 - Accuracy Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VSDdRplJQh7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=10, zoom_range=0.1,\n",
        "    width_shift_range=0.1, height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ],
      "metadata": {
        "id": "O5cpxRptUd3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "\n",
        "# Load test generator (you must re-create it like before)\n",
        "test_gen = val_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Load model\n",
        "model = load_model('/content/drive/MyDrive/saved_models/mnv2_fold1.h5')\n",
        "\n",
        "# Predict\n",
        "y_probs = model.predict(test_gen, verbose=1)\n",
        "y_pred = np.argmax(y_probs, axis=1)\n",
        "y_true = test_gen.classes\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=test_gen.class_indices.keys())\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title('Confusion Matrix - Fold 1')\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5CiARptNUDIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "r_H_3__4tjdJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ğŸ“Š Plot class distributions for ALL folds\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds):\n",
        "    print(f\"\\nğŸ”µ Class Distribution for Fold {fold_idx + 1}\\n\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # ğŸ§ª Training set\n",
        "    sns.countplot(ax=axes[0], data=train_df, x='labels', order=sorted(train_df['labels'].unique()))\n",
        "    axes[0].set_title(f\"Training Set - Fold {fold_idx + 1}\")\n",
        "    axes[0].set_xlabel(\"Class Label\")\n",
        "    axes[0].set_ylabel(\"Number of Images\")\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # ğŸ§ª Testing set\n",
        "    sns.countplot(ax=axes[1], data=test_df, x='labels', order=sorted(test_df['labels'].unique()))\n",
        "    axes[1].set_title(f\"Test Set - Fold {fold_idx + 1}\")\n",
        "    axes[1].set_xlabel(\"Class Label\")\n",
        "    axes[1].set_ylabel(\"Number of Images\")\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6PzGz-u12DW2"
      },
      "outputs": [],
      "source": [
        "#UPDATED\n",
        "#CNN FROM SCRATCH\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# CSV path to store results\n",
        "results_csv_path = \"/content/drive/MyDrive/saved_models/results.csv\"\n",
        "technique_name = \"CNN from scratch\"\n",
        "\n",
        "# Initialize results DataFrame\n",
        "if os.path.exists(results_csv_path):\n",
        "    results_df = pd.read_csv(results_csv_path)\n",
        "else:\n",
        "    results_df = pd.DataFrame(columns=[\n",
        "        \"Technique\", \"Set\", \"Fold\", \"Time(min)\", \"Epochs Trained\",\n",
        "        \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"\n",
        "    ])\n",
        "\n",
        "# ğŸ”µ Loop through each fold\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds):\n",
        "    print(f\"\\nğŸ”µ Fold {fold_idx + 1} starting...\\n\")\n",
        "\n",
        "    # â— Split train_df into 90% train and 10% validation\n",
        "    train_split_df, val_split_df = train_test_split(\n",
        "        train_df,\n",
        "        test_size=0.1,\n",
        "        stratify=train_df['labels'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # ğŸ”¹ Create Generators\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_split_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=val_split_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # ğŸ”¹ Create New Model\n",
        "    model = create_model()\n",
        "\n",
        "    # ğŸ”¹ Callbacks\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath=f\"/content/drive/MyDrive/saved_models/cnn_fold_{fold_idx + 1}_checkpoint.h5\",\n",
        "        monitor='val_loss',\n",
        "        save_best_only=False,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # â±ï¸ Start training\n",
        "    start_time = time.time()\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=40,\n",
        "        callbacks=[early_stop, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = (end_time - start_time) / 60\n",
        "    epochs_trained = len(history.history['loss'])\n",
        "\n",
        "    # ğŸ’¾ Save Final Model & History\n",
        "    model.save(f\"/content/drive/MyDrive/saved_models/cnn_fold_{fold_idx + 1}.h5\")\n",
        "    with open(f\"/content/drive/MyDrive/saved_models/history_fold_{fold_idx + 1}.pkl\", 'wb') as f:\n",
        "        pickle.dump(history.history, f)\n",
        "\n",
        "    # ğŸ§® Function to evaluate and append to results_df\n",
        "    def evaluate_and_log(set_name, generator):\n",
        "        global results_df\n",
        "        y_true = generator.classes\n",
        "        y_probs = model.predict(generator, verbose=0)\n",
        "        y_pred = y_probs.argmax(axis=1)\n",
        "\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        prec = precision_score(y_true, y_pred, average='weighted')\n",
        "        rec = recall_score(y_true, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        new_row = {\n",
        "            \"Technique\": technique_name,\n",
        "            \"Set\": set_name,\n",
        "            \"Fold\": fold_idx + 1,\n",
        "            \"Time(min)\": round(elapsed_time, 2),\n",
        "            \"Epochs Trained\": epochs_trained,\n",
        "            \"Accuracy\": acc,\n",
        "            \"Precision\": prec,\n",
        "            \"Recall\": rec,\n",
        "            \"F1 Score\": f1\n",
        "        }\n",
        "\n",
        "\n",
        "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "    # ğŸ” Evaluate Train, Validation, and Test\n",
        "    evaluate_and_log(\"Train\", train_generator)\n",
        "    evaluate_and_log(\"Validation\", val_generator)\n",
        "    evaluate_and_log(\"Test\", test_generator)\n",
        "\n",
        "    # ğŸ’¾ Save to CSV\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(f\"\\nâœ… Fold {fold_idx + 1} results saved to CSV.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3adQWkLh4D-z"
      },
      "outputs": [],
      "source": [
        "#updated\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Store accuracies and losses\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "\n",
        "# Evaluate each fold\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds):  # â¬…ï¸ CHANGED val_df â” test_df\n",
        "    print(f\"\\nğŸ”µ Evaluating Fold {fold_idx + 1}...\\n\")\n",
        "\n",
        "    # Reload the model\n",
        "    model = load_model(f\"/content/drive/MyDrive/saved_models/effb0_fold_{fold_idx + 1}.h5\") #CHANGE cnn_fold_\n",
        "\n",
        "    # Create test generator (based on test_df)\n",
        "    test_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Evaluate on the test generator\n",
        "    test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
        "\n",
        "    print(f\"ğŸ¯ Fold {fold_idx + 1} Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"ğŸ¯ Fold {fold_idx + 1} Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Save results\n",
        "    fold_accuracies.append(test_acc)\n",
        "    fold_losses.append(test_loss)\n",
        "\n",
        "# Calculate average results\n",
        "avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
        "avg_loss = sum(fold_losses) / len(fold_losses)\n",
        "\n",
        "print(\"\\nğŸ“ˆ Average over all Folds:\")\n",
        "print(f\"âœ… Average Test Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"âœ… Average Test Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnQrgpFj4rsl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle  # Needed to load the histories\n",
        "\n",
        "# Lists to collect history for all folds\n",
        "histories = []\n",
        "\n",
        "# ğŸ”µ Load each fold's saved history\n",
        "for fold_idx in range(4):\n",
        "    print(f\"\\nğŸ”µ Loading Training History for Fold {fold_idx + 1}...\\n\")\n",
        "\n",
        "    with open(f\"/content/drive/MyDrive/saved_models/history_fold_{fold_idx + 1}.pkl\", 'rb') as f:\n",
        "        history_data = pickle.load(f)\n",
        "        histories.append(history_data)\n",
        "\n",
        "# ğŸ–¼ï¸ Now plot for each fold\n",
        "for fold_idx, history_data in enumerate(histories):\n",
        "    print(f\"\\nğŸ–¼ï¸ Plotting Fold {fold_idx + 1}...\\n\")\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history_data['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history_data['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'Model Accuracy over Epochs - Fold {fold_idx + 1}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history_data['loss'], label='Train Loss')\n",
        "    plt.plot(history_data['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Model Loss over Epochs - Fold {fold_idx + 1}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpwHRxIT4_hk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#updated\n",
        "#PLOT CONFUSION MATRIXES\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ğŸŸ¡ Loop through each fold\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds):  # âœ… val_df âœ test_df\n",
        "    print(f\"\\nğŸ”µ Fold {fold_idx + 1} Confusion Matrix and Classification Report:\\n\")\n",
        "\n",
        "    # Create test generator\n",
        "    test_generator = val_datagen.flow_from_dataframe(  # âœ… val_generator âœ test_generator\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Load the saved model\n",
        "    model = load_model(f\"/content/drive/MyDrive/saved_models/tl_d121_fold_{fold_idx + 1}.h5\")\n",
        "\n",
        "    # Predict\n",
        "    y_pred_probs = model.predict(test_generator, verbose=1)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # True labels\n",
        "    y_true = test_generator.classes\n",
        "    class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title(f'Confusion Matrix - Fold {fold_idx + 1}')\n",
        "    plt.show()\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(y_true, y_pred_classes, target_names=class_labels)\n",
        "    print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Data generators â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #used for effnetb0 conf matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=10, zoom_range=0.1,\n",
        "    width_shift_range=0.1, height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "K = 4\n",
        "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
        "folds = []\n",
        "\n",
        "for train_idx, test_idx in skf.split(df['filepaths'], df['labels']):\n",
        "    train_data = df.iloc[train_idx].reset_index(drop=True)\n",
        "    test_data = df.iloc[test_idx].reset_index(drop=True)\n",
        "    folds.append((train_data, test_data))\n"
      ],
      "metadata": {
        "id": "Rn_euURRYvWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EfficientNetB0 Confusion Matrix\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Dummy placeholder for 'Cast'\n",
        "class DummyCast(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "# Register both required components\n",
        "custom_objects = {\n",
        "    'Cast': DummyCast,\n",
        "    'Policy': mixed_precision.Policy\n",
        "}\n",
        "\n",
        "# ğŸŸ¡ Loop through each fold\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds):\n",
        "    print(f\"\\nğŸ”µ Fold {fold_idx + 1} Confusion Matrix and Classification Report:\\n\")\n",
        "\n",
        "    # Create test generator\n",
        "    test_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # ğŸ”„ Load the correct model for the current fold inside the loop\n",
        "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "        model = load_model(f\"/content/drive/MyDrive/saved_models/effb0_fold{fold_idx + 1}.h5\")\n",
        "\n",
        "    # Predict\n",
        "    y_pred_probs = model.predict(test_generator, verbose=1)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # True labels\n",
        "    y_true = test_generator.classes\n",
        "    class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title(f'Confusion Matrix - Fold {fold_idx + 1}')\n",
        "    plt.show()\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(y_true, y_pred_classes, target_names=class_labels)\n",
        "    print(report)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EVAKDRqYWbME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mobile net v2 CONFUSION MATRIX\n",
        "for fold_idx, (_, test_df) in enumerate(folds):\n",
        "    print(f\"\\nğŸ”µ Fold {fold_idx + 1} Confusion Matrix and Classification Report:\\n\")\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    model_path = f\"/content/drive/MyDrive/saved_models/mnv2_fold{fold_idx + 1}.h5\"\n",
        "\n",
        "    # ğŸ‘‡ Fix loading error for mixed precision\n",
        "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "        model = load_model(model_path)\n",
        "\n",
        "    y_pred_probs = model.predict(test_gen, verbose=0)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_true = test_gen.classes\n",
        "    class_labels = list(test_gen.class_indices.keys())\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.title(f\"Confusion Matrix - Fold {fold_idx + 1}\")\n",
        "    plt.show()\n",
        "\n",
        "    print(classification_report(y_true, y_pred, target_names=class_labels))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cPfFxS_ggP70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vgg19 CONFUSION MATRIX\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Dummy placeholder for 'Cast'\n",
        "class DummyCast(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "# Register both required components\n",
        "custom_objects = {\n",
        "    'Cast': DummyCast,\n",
        "    'Policy': mixed_precision.Policy\n",
        "}\n",
        "\n",
        "# ğŸŸ¡ Loop through each fold\n",
        "for fold_idx, (train_df, test_df) in enumerate(folds):\n",
        "    print(f\"\\nğŸ”µ Fold {fold_idx + 1} Confusion Matrix and Classification Report:\\n\")\n",
        "\n",
        "    # Create test generator\n",
        "    test_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # ğŸ”„ Load the correct model for the current fold inside the loop\n",
        "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "        model = load_model(f\"/content/drive/MyDrive/saved_models/vgg19_fold{fold_idx + 1}.h5\")\n",
        "\n",
        "    # Predict\n",
        "    y_pred_probs = model.predict(test_generator, verbose=1)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # True labels\n",
        "    y_true = test_generator.classes\n",
        "    class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title(f'Confusion Matrix - Fold {fold_idx + 1}')\n",
        "    plt.show()\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(y_true, y_pred_classes, target_names=class_labels)\n",
        "    print(report)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nTMxpSb_o5sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#densenet121 CONFUSION MATRIX\n",
        "\n",
        "import numpy as np, seaborn as sns, matplotlib.pyplot as plt, tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# â”€â”€ custom-object safety net (needed when model saved with MP) â”€â”€\n",
        "class DummyCast(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "custom_objects = {\n",
        "    \"Cast\"  : DummyCast,         # for legacy mp layers\n",
        "    \"Policy\": mixed_precision.Policy\n",
        "}\n",
        "\n",
        "# â”€â”€ iterate through the four folds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for fold_idx, (_, test_df) in enumerate(folds, start=1):\n",
        "    print(f\"\\nğŸ”µ  Fold {fold_idx} â€“ Confusion Matrix & Report\\n\")\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe   = test_df,\n",
        "        x_col       = \"filepaths\",\n",
        "        y_col       = \"labels\",\n",
        "        target_size = IMG_SIZE,\n",
        "        batch_size  = BATCH_SIZE,\n",
        "        class_mode  = \"categorical\",\n",
        "        shuffle     = False)\n",
        "\n",
        "    # load DenseNet-121 model for this fold\n",
        "    model_path = f\"/content/drive/MyDrive/saved_models/mnv2_fold{fold_idx}.h5\"\n",
        "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "        model = load_model(model_path)\n",
        "\n",
        "    # predictions\n",
        "    y_prob = model.predict(test_gen, verbose=1)\n",
        "    y_pred = y_prob.argmax(axis=1)\n",
        "\n",
        "    # ground-truth\n",
        "    y_true        = test_gen.classes\n",
        "    class_labels  = list(test_gen.class_indices.keys())\n",
        "\n",
        "    # â”€â”€ confusion matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.title(f\"Confusion Matrix â€” DenseNet121 â€” Fold {fold_idx}\")\n",
        "    plt.xlabel(\"Predicted label\");  plt.ylabel(\"True label\")\n",
        "    plt.tight_layout();  plt.show()\n",
        "\n",
        "    # â”€â”€ classification report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(classification_report(y_true, y_pred, target_names=class_labels))\n"
      ],
      "metadata": {
        "id": "TzhDWaMuVhSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PLOT ROC CURVES FOR EACH CLASS (CNN FROM SCRATCH)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pickle\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 4\n",
        "FOLDS = 4\n",
        "from typing import List\n",
        "\n",
        "classnames: List[str] = [\"COVID\", \"Lung Opacity\", \"Normal\", \"Viral Pneumonia\"]\n",
        "\n",
        "# ImageDataGenerator (same as your CNN from scratch)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Loop through each fold\n",
        "for fold_idx in range(1, FOLDS + 1):\n",
        "    print(f\"\\nğŸ“Š ROC Curve for Fold {fold_idx}\")\n",
        "\n",
        "    # Get test dataframe\n",
        "    _, test_df = folds[fold_idx - 1]\n",
        "\n",
        "    # Load model\n",
        "    model_path = f\"/content/drive/MyDrive/saved_models/cnn_fold_{fold_idx}.h5\"\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Create test generator\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # True labels and predictions\n",
        "    y_true = test_gen.classes\n",
        "    y_true_bin = label_binarize(y_true, classes=list(range(NUM_CLASSES)))\n",
        "\n",
        "    y_probs = model.predict(test_gen, verbose=0)\n",
        "\n",
        "    # Plot ROC for each class\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(NUM_CLASSES):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{classnames[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.title(f\"ROC Curve â€“ Fold {fold_idx} â€“ CNN from Scratch\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bP5y0aQtEUx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PLOT  ROC CURVES FOR EACH CLASS (MOBILENETV2)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 4\n",
        "FOLDS = 4\n",
        "classnames = [\"COVID\", \"Lung Opacity\", \"Normal\", \"Viral Pneumonia\"]\n",
        "\n",
        "# Use correct MobileNetV2 preprocessing\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Model builder (same as training)\n",
        "def build_model(num_classes: int):\n",
        "    base = MobileNetV2(include_top=False, weights='imagenet', input_shape=IMG_SIZE + (3,))\n",
        "    base.trainable = True  # We're just using this to load weights\n",
        "    inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x = base(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Plot ROC curve for each fold\n",
        "for fold_idx in range(1, FOLDS + 1):\n",
        "    print(f\"\\nğŸ“Š ROC Curve for Fold {fold_idx} â€” MobileNetV2\")\n",
        "\n",
        "    # Get test set from folds\n",
        "    _, test_df = folds[fold_idx - 1]\n",
        "\n",
        "    # Generator for test data\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Build model and load weights\n",
        "    model = build_model(NUM_CLASSES)\n",
        "    weights_path = f\"/content/drive/MyDrive/saved_models/tl_mnv2_fold{fold_idx}_best.weights.h5\"\n",
        "    model.load_weights(weights_path)\n",
        "\n",
        "    # True labels and predicted probabilities\n",
        "    y_true = test_gen.classes\n",
        "    y_true_bin = label_binarize(y_true, classes=list(range(NUM_CLASSES)))\n",
        "    y_probs = model.predict(test_gen, verbose=0)\n",
        "\n",
        "    # Plot ROC curves per class\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(NUM_CLASSES):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{classnames[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.title(f\"ROC Curve â€“ Fold {fold_idx} â€“ MobileNetV2\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QGkGUwwlKzUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EfficientNetb0 ROC CURVES\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 4\n",
        "FOLDS = 4\n",
        "classnames = [\"COVID\", \"Lung Opacity\", \"Normal\", \"Viral Pneumonia\"]\n",
        "\n",
        "# EfficientNetB0 uses its own preprocessing\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Model builder (same as training)\n",
        "def build_model(num_classes: int):\n",
        "    base = EfficientNetB0(include_top=False, weights='imagenet', input_shape=IMG_SIZE + (3,))\n",
        "    base.trainable = True  # Required to allow weight loading\n",
        "    inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x = base(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Loop through each fold\n",
        "for fold_idx in range(1, FOLDS + 1):\n",
        "    print(f\"\\nğŸ“Š ROC Curve for Fold {fold_idx} â€” EfficientNetB0\")\n",
        "\n",
        "    # Load test set\n",
        "    _, test_df = folds[fold_idx - 1]\n",
        "\n",
        "    # Test generator\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Build model and load weights\n",
        "    model = build_model(NUM_CLASSES)\n",
        "    weights_path = f\"/content/drive/MyDrive/saved_models/effb0_fold{fold_idx}_best.weights.h5\"\n",
        "    model.load_weights(weights_path)\n",
        "\n",
        "    # Predict\n",
        "    y_true = test_gen.classes\n",
        "    y_true_bin = label_binarize(y_true, classes=list(range(NUM_CLASSES)))\n",
        "    y_probs = model.predict(test_gen, verbose=0)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(NUM_CLASSES):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{classnames[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.title(f\"ROC Curve â€“ Fold {fold_idx} â€“ EfficientNetB0\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qWhdCGm7robG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG19 ROC CURVES\n",
        "\n",
        "import numpy as np, matplotlib.pyplot as plt, tensorflow as tf, os\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# â”€â”€â”€ constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "IMG_SIZE     = (224, 224)\n",
        "BATCH_SIZE   = 32               # matches training batch for VGG-19\n",
        "NUM_CLASSES  = 4\n",
        "FOLDS        = 4\n",
        "CLASSNAMES   = [\"COVID\", \"Lung Opacity\", \"Normal\", \"Viral Pneumonia\"]\n",
        "\n",
        "# â”€â”€â”€ non-augmented generator for evaluation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# â”€â”€â”€ model builder (same head used during fine-tuning) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def build_vgg19_model(num_classes: int = NUM_CLASSES):\n",
        "    base = VGG19(include_top=False, weights='imagenet',\n",
        "                 input_shape=IMG_SIZE + (3,))\n",
        "    base.trainable = True  # required to load unfrozen weights\n",
        "    inputs  = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x = base(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax',\n",
        "                    dtype='float32')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# â”€â”€â”€ ROC plotting loop per fold â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for fold_idx in range(1, FOLDS + 1):\n",
        "    print(f\"\\nğŸ“Š ROC curve â€” Fold {fold_idx} â€” VGG-19\")\n",
        "\n",
        "    # split tuple (train_df, test_df) from your global `folds` list\n",
        "    _, test_df = folds[fold_idx - 1]\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe   = test_df,\n",
        "        x_col       = 'filepaths',\n",
        "        y_col       = 'labels',\n",
        "        target_size = IMG_SIZE,\n",
        "        batch_size  = BATCH_SIZE,\n",
        "        class_mode  = 'categorical',\n",
        "        shuffle     = False)\n",
        "\n",
        "    # build model & load best weights for this fold\n",
        "    model = build_vgg19_model(NUM_CLASSES)\n",
        "    weights_path = (f\"/content/drive/MyDrive/saved_models/\"\n",
        "                    f\"tl_vgg19_fold{fold_idx}_best.weights.h5\")\n",
        "    if not os.path.exists(weights_path):\n",
        "        raise FileNotFoundError(f\"â›” Weights not found: {weights_path}\")\n",
        "    model.load_weights(weights_path)\n",
        "\n",
        "    # predictions\n",
        "    y_true      = test_gen.classes                        # integer labels\n",
        "    y_true_bin  = label_binarize(y_true, classes=range(NUM_CLASSES))\n",
        "    y_prob      = model.predict(test_gen, verbose=0)      # (N, 4)\n",
        "\n",
        "    # ROC per class\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(NUM_CLASSES):\n",
        "        fpr, tpr, _   = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
        "        roc_auc       = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2,\n",
        "                 label=f\"{CLASSNAMES[i]}  (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.title(f\"ROC Curve â€“ Fold {fold_idx} â€“ VGG-19\")\n",
        "    plt.xlabel(\"False Positive Rate\");  plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\");  plt.grid(True);  plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NlTCqMEhoHg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ROC curves for the fine-tuned **DenseNet-121** on each fold\n",
        "# ---------------------------------------------------------------\n",
        "#  â€¢ Assumes the training cell saved:\n",
        "#      /content/drive/MyDrive/saved_models/d121_fold{fold}.h5\n",
        "#  â€¢ Uses the same DenseNet preprocessing\n",
        "#  â€¢ Plots one-vs-rest ROC + AUC for all four classes\n",
        "# ================================================================\n",
        "\n",
        "import os, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# â”€â”€ constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "IMG_SIZE    = (224, 224)\n",
        "BATCH_SIZE  = 48\n",
        "NUM_CLASSES = 4\n",
        "FOLDS       = 4\n",
        "CLASSNAMES  = [\"COVID\", \"Lung Opacity\", \"Normal\", \"Viral Pneumonia\"]\n",
        "\n",
        "# â”€â”€ val generator (no augmentation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# â”€â”€ custom-object map for mixed precision models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class DummyCast(tf.keras.layers.Layer):\n",
        "    def call(self, inputs): return inputs\n",
        "\n",
        "custom_objects = {\"Cast\": DummyCast, \"Policy\": mixed_precision.Policy}\n",
        "\n",
        "# â”€â”€ helper: rebuild DenseNet-121 head (needed to load weights) â”€â”€\n",
        "def build_d121_model(num_classes=NUM_CLASSES):\n",
        "    base = DenseNet121(include_top=False, weights=\"imagenet\",\n",
        "                       input_shape=IMG_SIZE + (3,))\n",
        "    base.trainable = True           # must match training state\n",
        "    inp = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x   = base(inp, training=False)\n",
        "    x   = GlobalAveragePooling2D()(x)\n",
        "    x   = Dropout(0.5)(x)\n",
        "    x   = Dense(256, activation=\"relu\")(x)\n",
        "    x   = Dropout(0.3)(x)\n",
        "    out = Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return Model(inp, out)\n",
        "\n",
        "# â”€â”€ fold loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for fold_idx, (_, test_df) in enumerate(folds, start=1):\n",
        "    print(f\"\\nğŸ“Š ROC curve â€” DenseNet121 â€” Fold {fold_idx}\")\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe   = test_df,\n",
        "        x_col       = \"filepaths\",\n",
        "        y_col       = \"labels\",\n",
        "        target_size = IMG_SIZE,\n",
        "        batch_size  = BATCH_SIZE,\n",
        "        class_mode  = \"categorical\",\n",
        "        shuffle     = False)\n",
        "\n",
        "    # build & load weights\n",
        "    model = build_d121_model()\n",
        "    weights_path = f\"/content/drive/MyDrive/saved_models/mnv2_fold{fold_idx}.h5\"\n",
        "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    # predictions\n",
        "    y_true      = test_gen.classes\n",
        "    y_true_bin  = label_binarize(y_true, classes=range(NUM_CLASSES))\n",
        "    y_prob      = model.predict(test_gen, verbose=0)\n",
        "\n",
        "    # plot ROC for each class\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(NUM_CLASSES):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
        "        roc_auc      = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2,\n",
        "                 label=f\"{CLASSNAMES[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "    plt.title(f\"ROC Curve â€“ DenseNet121 â€“ Fold {fold_idx}\")\n",
        "    plt.xlabel(\"False Positive Rate\");  plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\");  plt.grid(True);  plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Bac2f0A3W_zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ROC curves from *weights-only* checkpoints of DenseNet-121\n",
        "#  (files: tl_d121_fold{N}_best.weights.h5)\n",
        "# ================================================================\n",
        "\n",
        "import os, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# â”€â”€ constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "IMG_SIZE    = (224, 224)\n",
        "BATCH_SIZE  = 48\n",
        "NUM_CLASSES = 4\n",
        "FOLDS       = 4\n",
        "CLASSNAMES  = [\"COVID\", \"Lung Opacity\", \"Normal\", \"Viral Pneumonia\"]\n",
        "\n",
        "# â”€â”€ val generator (no augmentation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# â”€â”€ build DenseNet-121 with the *same* head you trained ----------\n",
        "def build_d121_model(num_classes=NUM_CLASSES):\n",
        "    base = DenseNet121(include_top=False, weights=\"imagenet\",\n",
        "                       input_shape=IMG_SIZE + (3,))\n",
        "    inp = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "    x   = base(inp, training=False)\n",
        "    x   = GlobalAveragePooling2D()(x)\n",
        "    x   = Dropout(0.5)(x)\n",
        "    x   = Dense(256, activation=\"relu\")(x)\n",
        "    x   = Dropout(0.3)(x)\n",
        "    out = Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return Model(inp, out)\n",
        "\n",
        "# â”€â”€ custom-object map for mixed precision (if model saved w/ MP) â€“\n",
        "class DummyCast(tf.keras.layers.Layer):\n",
        "    def call(self, inputs): return inputs\n",
        "custom_objects = {\"Cast\": DummyCast, \"Policy\": mixed_precision.Policy}\n",
        "\n",
        "# â”€â”€ fold loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for fold_idx, (_, test_df) in enumerate(folds, start=1):\n",
        "    print(f\"\\nğŸ“Š ROC curve â€” DenseNet121 â€” Fold {fold_idx}\")\n",
        "\n",
        "    test_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe   = test_df,\n",
        "        x_col       = \"filepaths\",\n",
        "        y_col       = \"labels\",\n",
        "        target_size = IMG_SIZE,\n",
        "        batch_size  = BATCH_SIZE,\n",
        "        class_mode  = \"categorical\",\n",
        "        shuffle     = False)\n",
        "\n",
        "    # build fresh model & load weights-only checkpoint\n",
        "    model = build_d121_model()\n",
        "    w_path = (f\"/content/drive/MyDrive/saved_models/\"\n",
        "              f\"tl_d121_fold{fold_idx}_best.weights.h5\")\n",
        "    if not os.path.exists(w_path):\n",
        "        raise FileNotFoundError(w_path)\n",
        "    model.load_weights(w_path)\n",
        "\n",
        "    # predictions\n",
        "    y_true      = test_gen.classes\n",
        "    y_true_bin  = label_binarize(y_true, classes=range(NUM_CLASSES))\n",
        "    y_prob      = model.predict(test_gen, verbose=0)\n",
        "\n",
        "    # plot ROC for each class\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(NUM_CLASSES):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
        "        roc_auc      = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2,\n",
        "                 label=f\"{CLASSNAMES[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "    plt.title(f\"ROC Curve â€“ DenseNet121 â€“ Fold {fold_idx}\")\n",
        "    plt.xlabel(\"False Positive Rate\");  plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\");  plt.grid(True);  plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SPlbtb7YaT5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNoiT6MmOj15ukm6Vn8R2ZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}